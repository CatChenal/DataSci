{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Pandas for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing details for Hypothesis Testing #\n",
    "\n",
    "## Definitions:##\n",
    "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
    "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n",
    "\n",
    "## The data files information:##\n",
    "* United States housing data from the Zillow research data site for [all homes at a city level](http://files.zillowstatic.com/research/public/City/City_Zhvi_AllHomes.csv), \n",
    "  ```City_Zhvi_AllHomes.csv```, has median home sale prices at a fine grained level.\n",
    "* From the Wikipedia page on college towns is a list of [university towns in the United States](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States) which has been copy and pasted into the file ```university_towns.txt```.\n",
    "* From Bureau of Economic Analysis, US Department of Commerce, the [GDP over time](http://www.bea.gov/national/index.htm#gdp) of the United States in current dollars (use the chained value in 2009 dollars), in quarterly intervals, in the file ```gdplev.xls```. For this assignment, only look at GDP data from the first quarter of 2000 onward.\n",
    "\n",
    "                                                                                   \n",
    "## **Hypothesis**:##\n",
    ">University towns have their mean housing prices less affected by recessions.\n",
    "                                                                                   \n",
    "###### Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. \n",
    "\n",
    ">(```price_ratio = quarter_before_recession/recession_bottom```)\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##  Helper functions ................................................................\n",
    "##\n",
    "def get_rec_qtr(gdp, what='start', start_qtr_flag=True):\n",
    "    qtr = None\n",
    "    which = { 'start':True, 'end':False}\n",
    "    \n",
    "    lix = len(gdp.index)\n",
    "    \n",
    "    if which[what]: \n",
    "        for i in range(2, lix):\n",
    "            if ( (gdp.BN_dollar_2009[i-2] > gdp.BN_dollar_2009[i-1]) & \n",
    "                 (gdp.BN_dollar_2009[i-1] > gdp.BN_dollar_2009[i]) ):\n",
    "            \n",
    "                if start_qtr_flag:\n",
    "                    qtr = gdp.index[i-1]\n",
    "                else:\n",
    "                    qtr = gdp.index[i-2]\n",
    "                break\n",
    "    else:\n",
    "        for i in range(2, lix):\n",
    "            if ( (gdp.BN_dollar_2009[i-2] < gdp.BN_dollar_2009[i-1]) &\n",
    "                 (gdp.BN_dollar_2009[i-1] < gdp.BN_dollar_2009[i]) ):\n",
    "                qtr = gdp.index[i]\n",
    "                break\n",
    "            else:\n",
    "                qtr = None\n",
    "            \n",
    "    return qtr\n",
    "\n",
    "\n",
    "def get_GDP():\n",
    "    \"\"\"\n",
    "    File gdplev.xls has the GDP of the United States in quarterly intervals\n",
    "    in current dollars (use the chained value in 2009 dollars).\n",
    "    Only look at GDP data from the first quarter of 2000 onward.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel( './data/gdplev.xls')\n",
    "    df = df[[ df.columns[-4], df.columns[-2] ]]\n",
    "    df.rename_axis( {df.columns[0]:'Q', df.columns[1]:'BN_dollar_2009'}, axis=1, inplace=True)\n",
    "    \n",
    "    # Get yr 2000 onward:\n",
    "    B2K = df.loc[df.Q.str[:4]=='2000'].index[0]\n",
    "    df.drop(df.index[0:B2K], axis=0, inplace=True)\n",
    "    \n",
    "    df['BN_dollar_2009'] = df['BN_dollar_2009'].astype('float64')\n",
    "    df['Q'] = pd.PeriodIndex( df['Q'], freq='Q-DEC')\n",
    "    df = df.set_index('Q')\n",
    "    # return Period to string\n",
    "    df.rename_axis(lambda x: str(x).lower(), axis=0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "#  Answer functions  ..................................................................................\n",
    "#\n",
    "def get_list_of_university_towns():\n",
    "    utowns = pd.read_table( './data/university_towns.txt', sep='\\n', header=None, names = ['RegionName'])\n",
    "    \n",
    "    # cleanup here\n",
    "    states_idx = utowns[utowns.RegionName.str.contains('edit')].index\n",
    "    utowns['State'] = utowns.RegionName.str.extract('([\\w\\s]+)\\[edit\\]', expand=False).fillna(method='ffill')\n",
    "    \n",
    "    # drop & re-index after row-drop\n",
    "    utowns.drop(states_idx, axis=0, inplace=True)\n",
    "    utowns.reset_index(inplace=True)\n",
    "    \n",
    "    utowns['RegionName'] = utowns.RegionName.str.extract('([\\w\\s,]+)\\s\\(', expand=False)\n",
    "    utowns['RegionName'] = utowns.RegionName.str.strip()\n",
    "    \n",
    "    # reorder columns\n",
    "    utowns = utowns[['State', 'RegionName']]\n",
    "\n",
    "    return utowns\n",
    "\n",
    "\n",
    "def get_recession_start():\n",
    "    \"\"\"\n",
    "    A recession:: start = two consecutive quarters of GDP decline\n",
    "                  end   = two consecutive quarters of GDP growth.\n",
    "    Returns the recession start as a string value in this format 2005q3\n",
    "    start_qtr=False is used in the ttest function to get preceding qtr.\n",
    "    \"\"\"\n",
    "    GDP = get_GDP()\n",
    "    q1 = get_rec_qtr(GDP, what='start')\n",
    "    return q1\n",
    "\n",
    "\n",
    "def get_recession_end():\n",
    "    \"\"\"\n",
    "    A recession:: start = two consecutive quarters of GDP decline\n",
    "                  end   = two consecutive quarters of GDP growth.\n",
    "    Returns the year and quarter of the recession end time as a \n",
    "    string value in this format 2005q3\n",
    "    \"\"\"\n",
    "    rec_start = get_recession_start()\n",
    "    GDP = get_GDP()\n",
    "    GDP = GDP[rec_start:]\n",
    "    \n",
    "    q2 = get_rec_qtr(GDP, what='end')\n",
    "    return q2\n",
    "\n",
    "\n",
    "def get_recession_bottom():\n",
    "    \"\"\"\n",
    "    A recession bottom is the quarter within a recession which had the lowest GDP.\n",
    "    Returns the year and quarter of the recession bottom time as a \n",
    "    string value in this format 2005q3\n",
    "    \"\"\"\n",
    "    rec_start = get_recession_start()\n",
    "    rec_end = get_recession_end()\n",
    "\n",
    "    GDP = get_GDP()\n",
    "    GDP = GDP[rec_start:rec_end]\n",
    "    \n",
    "    min_val = GDP.BN_dollar_2009.min()\n",
    "    min_idx = GDP[GDP.BN_dollar_2009 == min_val].index\n",
    "\n",
    "    # below: to use if GDP index is kept as quarterly Period:\n",
    "    #rec_bottom = '{}q{}'.format(min_idx[0].year, min_idx[0].quarter )\n",
    "    rec_bottom = min_idx[0]\n",
    "\n",
    "    return rec_bottom\n",
    "\n",
    "\n",
    "def convert_housing_data_to_quarters():\n",
    "    states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', \n",
    "          'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', \n",
    "          'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', \n",
    "          'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho',\n",
    "          'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', \n",
    "          'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', \n",
    "          'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', \n",
    "          'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', \n",
    "          'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut',\n",
    "          'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', \n",
    "          'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California',\n",
    "          'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', \n",
    "          'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', \n",
    "          'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}\n",
    "    \n",
    "    \"\"\"\n",
    "    City_Zhvi_AllHomes.csv, has median home sale prices at a fine grained level.\n",
    "    Converts the housing data to quarters and returns it as mean values in a dataframe. \n",
    "    This dataframe should be a dataframe with columns for 2000q1 through 2016q3, and \n",
    "    should have a multi-index in the shape of [\"State\",\"RegionName\"].\n",
    "    The resulting dataframe should have 67 columns, and 10,730 rows.\n",
    "    \"\"\"\n",
    "    housing = pd.read_csv( './data/City_Zhvi_AllHomes.csv', header=0)\n",
    "    \n",
    "    housing.drop(housing.columns[3:51], axis=1, inplace=True)\n",
    "    housing.drop(housing.columns[0], axis=1, inplace=True)\n",
    "    \n",
    "    # change the state abbreviation to full name to match university towns df:\n",
    "    housing[\"State\"].replace(states, inplace = True)\n",
    "    \n",
    "    # set MultiIndex\n",
    "    housing = housing.set_index(['State','RegionName'])\n",
    "    \n",
    "    # group into quarters Period\n",
    "    qtr_cols = pd.PeriodIndex(housing.columns, freq='M').asfreq('Q-DEC', 's')\n",
    "    \n",
    "    # grouping per quarterly Period:\n",
    "    grouped = housing.groupby(qtr_cols, axis=1).agg(np.mean)\n",
    "    \n",
    "    # back conversion to string to get the required lowercase format '2000q1':\n",
    "    grouped = grouped.rename(columns=lambda x: str(x).lower())\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "\n",
    "def run_ttest():\n",
    "    from scipy.stats import ttest_ind\n",
    "    import pandas as pd\n",
    "    \"\"\"\n",
    "    Runs a ttest comparing the university town values to the non-university towns values, \n",
    "    return whether the alternative hypothesis (that the two groups are the same)\n",
    "    is true or not as well as the p-value of the confidence. \n",
    "    Return the tuple (different, p, better) where \n",
    "    different=True if the t-test is True at a p<0.01 (we reject the null hypothesis), or \n",
    "    different=False if otherwise (we cannot reject the null hypothesis). \n",
    "    The variable p should be equal to the exact p value returned from scipy.stats.ttest_ind(). \n",
    "    The value for better should be either \"university town\" or \"non-university town\"\n",
    "    depending on which has a lower mean price ratio (which is equivalent to a reduced market loss).\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"create new data showing the decline or growth of housing prices\n",
    "    between the recession start and the recession bottom.\"\"\"\n",
    "    \n",
    "    utowns = get_list_of_university_towns()\n",
    "    hous_df1 = convert_housing_data_to_quarters()\n",
    "    \n",
    "    hous = pd.merge( hous_df1.reset_index(), utowns, \n",
    "                     on=utowns.columns.tolist(), \n",
    "                     indicator='_id', how='outer' )\n",
    "\n",
    "    # get the 2 periods of interest\n",
    "    GDP = get_GDP()\n",
    "    q_bef_start = get_rec_qtr(GDP, what='start', start_qtr_flag=False)\n",
    "    rec_bottom = get_recession_bottom()\n",
    "    \n",
    "    hous['Ratio'] = hous[q_bef_start].div(hous[rec_bottom])\n",
    "    \n",
    "    # u-towns data\n",
    "    hous_utowns = hous[hous['_id'] == 'both']\n",
    "    Ratio_u = hous_utowns.Ratio.dropna()\n",
    "    \n",
    "    # others\n",
    "    hous_not_utowns = hous[hous['_id'] != 'both']\n",
    "    Ratio_not_u = hous_not_utowns.Ratio.dropna()\n",
    "    \n",
    "    \"\"\"\n",
    "    The value for better should be either \"university town\" or \"non-university town\"\n",
    "    depending on which has a lower mean price ratio (which is equivalent to a reduced market loss).\n",
    "    \"\"\"\n",
    "    better = 'university town' if (Ratio_u.mean() < Ratio_not_u.mean()) else 'non-university town'\n",
    "    \n",
    "    \"\"\"\n",
    "    Run a ttest comparing the university town values to the non-university towns values, \n",
    "    return whether the alternative hypothesis **(that the two groups are the same)**\n",
    "    is true or not as well as the p-value of the confidence. \n",
    "    #\n",
    "    Is Docstring right?? \n",
    "    If alt hypo == \"the two groups are the same\", then the null hypo,\n",
    "            H_0 == \"two population w/unequal variances => Welch's test\n",
    "            ==> equal_var=False needed in the function call.\n",
    "    #\n",
    "    ttest_ind <equal_var> Parameter:\n",
    "        True (def):: perform a standard independent 2 sample test where H_0 = equal variances\n",
    "        False     :: perform Welch's t-test where H_0 = unequal population variances\n",
    "        \n",
    "    However, the answer is not accepted when the above logic is applied.\n",
    "    #\n",
    "    Return the tuple (different, p, better) where \n",
    "    different=True if the t-test is True at a p<0.01 (we reject the null hypothesis), or \n",
    "    different=False if otherwise (we cannot reject the null hypothesis).\n",
    "    \"\"\"\n",
    "    stats, pval = ttest_ind( Ratio_u, Ratio_not_u, equal_var=False )\n",
    "    different = (pval < 0.01)\n",
    "  \n",
    "    return (different, pval, better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_list_of_university_towns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recession_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recession_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recession_bottom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_housing_data_to_quarters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.00044454912338074125, 'university town')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ttest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "Il9Fx",
   "launcher_item_id": "TeDW0",
   "part_id": "WGlun"
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
